{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaisacht/Project/blob/main/Resnet1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phNA0Ess1um1"
      },
      "outputs": [],
      "source": [
        "#khai báo các thư viện \n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iC2Oe7qdGFll"
      },
      "outputs": [],
      "source": [
        "#khi khởi tạo ngẫu nhiên một dây số sẽ sinh ra như lân trước đó\n",
        "np.random.seed(813306)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8jfpKmu2Jaj"
      },
      "outputs": [],
      "source": [
        "#Xây dựng model\n",
        "def build_resnet(input_shape, n_feature_maps, nb_classes):\n",
        "    x = keras.layers.Input(shape=(input_shape))\n",
        "    conv_x = keras.layers.BatchNormalization()(x)\n",
        "    conv_x = keras.layers.Conv2D(n_feature_maps, 8, 1, padding='same')(conv_x)\n",
        "    conv_x = keras.layers.BatchNormalization()(conv_x)\n",
        "    conv_x = keras.layers.Activation('relu')(conv_x)\n",
        "     \n",
        "    conv_y = keras.layers.Conv2D(n_feature_maps, 5, 1, padding='same')(conv_x)\n",
        "    conv_y = keras.layers.BatchNormalization()(conv_y)\n",
        "    conv_y = keras.layers.Activation('relu')(conv_y)\n",
        "     \n",
        "    conv_z = keras.layers.Conv2D(n_feature_maps, 3, 1, padding='same')(conv_y)\n",
        "    conv_z = keras.layers.BatchNormalization()(conv_z)\n",
        "     \n",
        "    is_expand_channels = not (input_shape[-1] == n_feature_maps)\n",
        "    if is_expand_channels:\n",
        "        shortcut_y = keras.layers.Conv2D(n_feature_maps, 1, 1,padding='same')(x)\n",
        "        shortcut_y = keras.layers.BatchNormalization()(shortcut_y)\n",
        "    else:\n",
        "        shortcut_y = keras.layers.BatchNormalization()(x)\n",
        "        \n",
        "    y = keras.layers.Add()([shortcut_y, conv_z])\n",
        "    y = keras.layers.Activation('relu')(y)\n",
        "     \n",
        "    x1 = y\n",
        "    conv_x = keras.layers.Conv2D(n_feature_maps*2, 8, 1, padding='same')(x1)\n",
        "    conv_x = keras.layers.BatchNormalization()(conv_x)\n",
        "    conv_x = keras.layers.Activation('relu')(conv_x)\n",
        "    \n",
        "    conv_y = keras.layers.Conv2D(n_feature_maps*2, 5, 1, padding='same')(conv_x)\n",
        "    conv_y = keras.layers.BatchNormalization()(conv_y)\n",
        "    conv_y = keras.layers.Activation('relu')(conv_y)\n",
        "     \n",
        "    conv_z = keras.layers.Conv2D(n_feature_maps*2, 3, 1, padding='same')(conv_y)\n",
        "    conv_z = keras.layers.BatchNormalization()(conv_z)\n",
        "     \n",
        "    is_expand_channels = not (input_shape[-1] == n_feature_maps*2)\n",
        "    if is_expand_channels:\n",
        "        shortcut_y = keras.layers.Conv2D(n_feature_maps*2, 1, 1,padding='same')(x1)\n",
        "        shortcut_y = keras.layers.BatchNormalization()(shortcut_y)\n",
        "    else:\n",
        "        shortcut_y = keras.layers.BatchNormalization()(x1)\n",
        "\n",
        "    y = keras.layers.Add()([shortcut_y, conv_z])\n",
        "    y = keras.layers.Activation('relu')(y)\n",
        "     \n",
        "    x1 = y\n",
        "    conv_x = keras.layers.Conv2D(n_feature_maps*2, 8, 1, padding='same')(x1)\n",
        "    conv_x = keras.layers.BatchNormalization()(conv_x)\n",
        "    conv_x = keras.layers.Activation('relu')(conv_x)\n",
        "     \n",
        "    conv_y = keras.layers.Conv2D(n_feature_maps*2, 5, 1, padding='same')(conv_x)\n",
        "    conv_y = keras.layers.BatchNormalization()(conv_y)\n",
        "    conv_y = keras.layers.Activation('relu')(conv_y)\n",
        "     \n",
        "    conv_z = keras.layers.Conv2D(n_feature_maps*2, 3, 1, padding='same')(conv_y)\n",
        "    conv_z = keras.layers.BatchNormalization()(conv_z)\n",
        "\n",
        "    is_expand_channels = not (input_shape[-1] == n_feature_maps*2)\n",
        "    if is_expand_channels:\n",
        "        shortcut_y = keras.layers.Conv2D(n_feature_maps*2, 1, 1,padding='same')(x1)\n",
        "        shortcut_y = keras.layers.BatchNormalization()(shortcut_y)\n",
        "    else:\n",
        "        shortcut_y = keras.layers.BatchNormalization()(x1)\n",
        "    y = keras.layers.Add()([shortcut_y, conv_z])\n",
        "    y = keras.layers.Activation('relu')(y)\n",
        "     \n",
        "    full = keras.layers.GlobalAveragePooling2D()(y)\n",
        "    out = keras.layers.Dense(nb_classes, activation='softmax')(full)\n",
        "    return x, out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yM2WkkXa850D"
      },
      "outputs": [],
      "source": [
        "#tải tệp lên\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rW_cZ3LPPMg8"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cl1T_3KO2Noi"
      },
      "outputs": [],
      "source": [
        "#hàm tách nhãn và dữ liệu tương ứng trong 1 hàng, vị trí thứ 0 là nhãn và các vị trí còn lại là dữ liệu\n",
        "def readucr(filename):\n",
        "    data = np.loadtxt(filename, delimiter = ',')\n",
        "    Y = data[:,0]\n",
        "    X = data[:,1:]\n",
        "    return X, Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPgHnJkL2Q7a"
      },
      "outputs": [],
      "source": [
        "#số bước thực hiện train là 1500\n",
        "nb_epochs = 1500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HfgvgPc12bhq"
      },
      "outputs": [],
      "source": [
        "#lấy ra các tập test và train nhãn và dữ liệu tương ứng\n",
        "x_train, y_train = readucr('path to file.txt')\n",
        "x_test, y_test = readucr('path to file test.txt')\n",
        "#tính số lượng nhãn\n",
        "nb_classes = len(np.unique(y_test))\n",
        "#tính tham số batch\n",
        "batch_size = min(x_train.shape[0]/10, 16)\n",
        "#do tập dữ liệu được đánh nhãn từ 1 nên chuẩn hóa lại bộ dữ liệu được đánh nhãn từ 0     \n",
        "y_train = (y_train - y_train.min())/(y_train.max()-y_train.min())*(nb_classes-1)\n",
        "y_test = (y_test - y_test.min())/(y_test.max()-y_test.min())*(nb_classes-1)\n",
        "#?\n",
        "Y_train = keras.utils.to_categorical(y_train, nb_classes)\n",
        "Y_test = keras.utils.to_categorical(y_test, nb_classes)\n",
        "#giá trị trung bình của mảng x_train\n",
        "x_train_mean = x_train.mean()\n",
        "#tính phương sai của mảng x_train\n",
        "x_train_std = x_train.std()\n",
        "#chuẩn hóa lại mảng x_train\n",
        "x_train = (x_train - x_train_mean)/(x_train_std)\n",
        "#chuẩn hóa lại mảng x_test\n",
        "x_test = (x_test - x_train_mean)/(x_train_std)\n",
        "#set kích thưởng của mảng x sẽ có dạng (x_train.shape,1,1)\n",
        "x_train = x_train.reshape(x_train.shape + (1,1,))\n",
        "x_test = x_test.reshape(x_test.shape + (1,1,))\n",
        "#tính toán x,y qua model đã build     \n",
        "x , y = build_resnet(x_train.shape[1:], 64, nb_classes)\n",
        "\n",
        "model = keras.models.Model(inputs=x, outputs=y)\n",
        "\n",
        "optimizer = keras.optimizers.Adam()\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=optimizer,\n",
        "                  metrics=['accuracy'])\n",
        "      \n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5,\n",
        "                      patience=50, min_lr=0.0001) \n",
        "#train modle\n",
        "hist = model.fit(x_train, Y_train, batch_size=batch_size, epochs=nb_epochs,\n",
        "              verbose=1, validation_data=(x_test, Y_test), callbacks = [reduce_lr])\n",
        "log = pd.DataFrame(hist.history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKp513caM4pU"
      },
      "outputs": [],
      "source": [
        "#in log quá trình trainning\n",
        "print(log)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4rx3FYoTPDpk"
      },
      "outputs": [],
      "source": [
        "#lấy ra hàng có giá trị loss nhỏ nhất\n",
        "log_np = np.array(log)\n",
        "log_np\n",
        "min_index = (np.argmin(log_np, axis=0))\n",
        "print(log_np[min_index[0]])\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyML0FL6pIKlA7jh0Ltk3eH4",
      "include_colab_link": true,
      "mount_file_id": "1OEKH64Kips06IeGjhXBn2YdPWcOqa0Mi",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
